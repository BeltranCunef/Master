library(party)
library(readxl)
library(fastDummies)
library(ggplot2)
library(MASS)
library(car)
set.seed(1234)
datos <- read_excel("Datos tarea1.xlsx")
View(datos)
datos <- dplyr::select(datos, -Sexo, -EC, -A)
riesgo_Alto <- subset(datos, datos$TIPO == "Alto riesgo")
riesgo_Alto <- dplyr::select(riesgo_Alto, -c("TIPO"))
riesgo_Medio <- subset(datos, datos$TIPO == "Riesgo medio")
riesgo_Medio <- dplyr::select(riesgo_Medio, -c("TIPO"))
riesgo_Bajo <- subset(datos, datos$TIPO == "Bajo riesgo")
riesgo_Bajo <- dplyr::select(riesgo_Bajo, -c("TIPO"))
shapiro.test(datos$I)
shapiro.test(datos$Edad)
shapiro.test(datos$H)
shapiro.test(datos$P)
shapiro.test(datos$R)
datos_lda <- lda(TIPO~., data = datos)
datos_lda
datos_lda_values <- predict(datos_lda)
ldahist(data = datos_lda_values$x[,1], g = datos$TIPO)
ldahist(data = datos_lda_values$x[,2], g = datos$TIPO)
plot(datos_lda_values$x[,1],datos_lda_values$x[,2])
text(datos_lda_values$x[,1],datos_lda_values$x[,2], datos$TIPO, cex = 0.7, pos = 4, col = "red")
table(predict(datos_lda)$class, datos$TIPO)
datos_qda <- qda(TIPO~., data = datos)
datos_qda
datos_qda_values <- predict(datos_qda)
qdahist(data = datos_qda_values$x[,1], g = datos$TIPO)
table(datos_qda_values$class, datos$TIPO)
train <- sample(nrow(df), 0.7*nrow(df)) # muestra aleatoria de aprendizaje del arbol
train <- sample(nrow(datos), 0.7*nrow(datos)) # muestra aleatoria de aprendizaje del arbol
datos_train <- datos[train,] # muestra de entrenamiento
datos_validate <- datos[-train,] # muestra de validaciÃ³n
table(datos_train$class)
table(datos_validate$class)
View(datos_validate)
table(datos_train$TIPO)
table(datos_validate$TIPO)
arbol <- rpart(TIPO ~ ., data = datos_train, method = "class",
parms = list(split = "information"))
print(arbol)
summary(arbol)
arbol$cptable
plotcp(arbol)
arbol.podado <- prune(arbol, cp = 0.1891892)
prp(arbol.podado, type = 2, extra = 104,
fallen.leaves = TRUE, main = "Decision Tree")
prp(arbol.podado, type = 3, extra = 104,
fallen.leaves = TRUE, main = "Decision Tree")
prp(arbol.podado, type = 2, extra = 104,
fallen.leaves = TRUE, main = "Decision Tree")
plot(as.party(arbol.podado))
fit.ctree <- ctree(TIPO~., data = datos_train)
View(datos_train)
fit.ctree <- ctree(as.factor(TIPO)~., data = datos_train)
plot(fit.ctree, main = "Conditional Inference Tree")
ctree.pred <- predict(fit.ctree, datos_validate, type = "response")
ctree.perf <- table(datos_validate$TIPO, ctree.pred,
dnn = c("Actual", "Predicted"))
ctree.perf
View(datos_train)
knitr::opts_chunk$set(echo = TRUE)
library(rpart)
library(rpart.plot)
library(partykit)
library(party)
library(readxl)
library(fastDummies)
library(ggplot2)
library(MASS)
library(car)
set.seed(1234)
datos <- read_excel("Datos tarea1.xlsx")
View(datos)
summary(datos)
datos <- dummy_columns(datos, select_columns = c("Sexo", "EC", "A"))
datos <- dplyr::select(datos, -Sexo, -EC, -A)
riesgo_Alto <- subset(datos, datos$TIPO == "Alto riesgo")
riesgo_Alto <- dplyr::select(riesgo_Alto, -c("TIPO"))
riesgo_Medio <- subset(datos, datos$TIPO == "Riesgo medio")
riesgo_Medio <- dplyr::select(riesgo_Medio, -c("TIPO"))
riesgo_Bajo <- subset(datos, datos$TIPO == "Bajo riesgo")
riesgo_Bajo <- dplyr::select(riesgo_Bajo, -c("TIPO"))
summary(riesgo_Alto)
View(riesgo_Alto)
View(riesgo_Alto)
sum(riesgo_Alto$EC_SOLTERO)
sum(riesgo_Alto$EC_SOLTERO)
sum(riesgo_Alto$EC_CASADO)
summary(riesgo_Medio)
summary(riesgo_Medio)
summary(riesgo_Alto)
summary(riesgo_Bajo)
datos <- read_excel("Datos tarea1.xlsx")
datos <- dummy_columns(datos, select_columns = c("Sexo", "EC", "A"))
datos$Sexo_HOMBRE <- as.factor(datos$Sexo_HOMBRE)
datos$Sexo_MUJER <- as.factor(datos$Sexo_MUJER)
datos$EC_SOLTERO <- as.factor(datos$EC_SOLTERO)
datos$EC_CASADO <- as.factor(datos$EC_CASADO)
datos$A_BAJO <- as.factor(datos$A_BAJO)
datos$A_MEDIO <- as.factor(datos$A_MEDIO)
datos$A_ALTO <- as.factor(datos$A_ALTO)
datos <- dplyr::select(datos, -Sexo, -EC, -A)
riesgo_Alto <- subset(datos, datos$TIPO == "Alto riesgo")
riesgo_Alto <- dplyr::select(riesgo_Alto, -c("TIPO"))
riesgo_Medio <- subset(datos, datos$TIPO == "Riesgo medio")
riesgo_Medio <- dplyr::select(riesgo_Medio, -c("TIPO"))
riesgo_Bajo <- subset(datos, datos$TIPO == "Bajo riesgo")
riesgo_Bajo <- dplyr::select(riesgo_Bajo, -c("TIPO"))
summary(riesgo_Alto)
summary(riesgo_Medio)
summary(riesgo_Bajo)
datos_lda <- lda(TIPO~., data = datos)
datos_lda
datos_lda_values <- predict(datos_lda)
ldahist(data = datos_lda_values$x[,1], g = datos$TIPO)
ldahist(data = datos_lda_values$x[,2], g = datos$TIPO)
datos <- dplyr::select(datos, -Sexo_MUJER, -Sexo_HOMBRE, -EC_CASADO, -EC_SOLTERO, -A_ALTO, -A_MEDIO, -A_BAJO)
datos_lda <- lda(TIPO~., data = datos)
datos_lda
datos_lda_values <- predict(datos_lda)
ldahist(data = datos_lda_values$x[,1], g = datos$TIPO)
ldahist(data = datos_lda_values$x[,2], g = datos$TIPO)
plot(datos_lda_values$x[,1],datos_lda_values$x[,2])
text(datos_lda_values$x[,1],datos_lda_values$x[,2], datos$TIPO, cex = 0.7, pos = 4, col = "red")
plot(datos_lda_values$x[,1],datos_lda_values$x[,2])
text(datos_lda_values$x[,1],datos_lda_values$x[,2], datos$TIPO, cex = 0.7, pos = 4, col = "red")
table(predict(datos_lda)$class, datos$TIPO)
table(predict(datos_lda)$class, datos$TIPO)
library(car)
data(wine, package = 'rattle')
head(wine)
scatterplotMatrix(wine[2:6])
scatterplotMatrix(wine[7:14])
library(MASS)
wine.lda <- lda(Type ~ ., data = wine)
wine.lda
View(wine)
datos <- read_excel("Datos tarea1.xlsx")
datos <- dplyr::select(datos, -Sexo, -EC, -A)
datos_lda <- lda(TIPO~., data = datos)
datos_lda
datos_lda_values <- predict(datos_lda)
error <- mean(datos$TIPO != datos_lda_values$class) * 100
paste("Error: ", error, "%")
knitr::opts_chunk$set(echo = TRUE)
library(rpart)
library(rpart.plot)
library(partykit)
library(party)
library(readxl)
library(fastDummies)
library(ggplot2)
library(MASS)
library(car)
set.seed(1234)
datos <- read_excel("Datos tarea1.xlsx")
datos <- dummy_columns(datos, select_columns = c("Sexo", "EC", "A"))
datos$Sexo_HOMBRE <- as.factor(datos$Sexo_HOMBRE)
datos$Sexo_MUJER <- as.factor(datos$Sexo_MUJER)
datos$EC_SOLTERO <- as.factor(datos$EC_SOLTERO)
datos$EC_CASADO <- as.factor(datos$EC_CASADO)
datos$A_BAJO <- as.factor(datos$A_BAJO)
datos$A_MEDIO <- as.factor(datos$A_MEDIO)
datos$A_ALTO <- as.factor(datos$A_ALTO)
datos <- dplyr::select(datos, -Sexo, -EC, -A)
riesgo_Alto <- subset(datos, datos$TIPO == "Alto riesgo")
riesgo_Alto <- dplyr::select(riesgo_Alto, -c("TIPO"))
riesgo_Medio <- subset(datos, datos$TIPO == "Riesgo medio")
riesgo_Medio <- dplyr::select(riesgo_Medio, -c("TIPO"))
riesgo_Bajo <- subset(datos, datos$TIPO == "Bajo riesgo")
riesgo_Bajo <- dplyr::select(riesgo_Bajo, -c("TIPO"))
View(riesgo_Alto)
scatterplotMatrix(riesgo_Alto[1:5])
scatterplotMatrix(riesgo_Alto[1:5])
shapiro.test(riesgo_Alto$I)
shapiro.test(riesgo_Alto$Edad)
shapiro.test(riesgo_Alto$H)
shapiro.test(riesgo_Alto$P)
shapiro.test(riesgo_Alto$R)
scatterplotMatrix(riesgo_Medio[1:5])
shapiro.test(riesgo_Medio$I)
shapiro.test(riesgo_Medio$Edad)
shapiro.test(riesgo_Medio$H)
shapiro.test(riesgo_Medio$P)
shapiro.test(riesgo_Medio$R)
scatterplotMatrix(riesgo_Bajo[1:5])
shapiro.test(riesgo_Bajo$I)
shapiro.test(riesgo_Bajo$Edad)
shapiro.test(riesgo_Bajo$H)
shapiro.test(riesgo_Bajo$P)
shapiro.test(riesgo_Bajo$R)
library(biotools)
install.packages("biotools")
library(biotools)
View(datos)
boxM(data = datos[2:6], grouping = datos[1])
boxM(data = datos[,2:6], grouping = datos[,1])
View(datos)
boxM(data = datos[,2:6], grouping = datos[,1])
boxM(data = datos[,2:6], grouping = datos[,"TIPO"])
error <- mean(datos$TIPO != datos_Qda_values$class) * 100
datos_qda <- qda(TIPO~., data = datos)
library(rpart)
library(rpart.plot)
library(partykit)
library(party)
library(readxl)
library(fastDummies)
library(ggplot2)
library(MASS)
library(biotools)
library(car)
set.seed(1234)
datos <- read_excel("Datos tarea1.xlsx")
View(datos)
summary(datos)
datos <- dummy_columns(datos, select_columns = c("Sexo", "EC", "A"))
datos$Sexo_HOMBRE <- as.factor(datos$Sexo_HOMBRE)
datos$Sexo_MUJER <- as.factor(datos$Sexo_MUJER)
datos$EC_SOLTERO <- as.factor(datos$EC_SOLTERO)
datos$EC_CASADO <- as.factor(datos$EC_CASADO)
datos$A_BAJO <- as.factor(datos$A_BAJO)
datos$A_MEDIO <- as.factor(datos$A_MEDIO)
datos$A_ALTO <- as.factor(datos$A_ALTO)
datos <- dplyr::select(datos, -Sexo, -EC, -A)
riesgo_Alto <- subset(datos, datos$TIPO == "Alto riesgo")
riesgo_Alto <- dplyr::select(riesgo_Alto, -c("TIPO"))
riesgo_Medio <- subset(datos, datos$TIPO == "Riesgo medio")
riesgo_Medio <- dplyr::select(riesgo_Medio, -c("TIPO"))
riesgo_Bajo <- subset(datos, datos$TIPO == "Bajo riesgo")
riesgo_Bajo <- dplyr::select(riesgo_Bajo, -c("TIPO"))
summary(riesgo_Alto)
scatterplotMatrix(riesgo_Alto[1:5])
shapiro.test(riesgo_Alto$I)
shapiro.test(riesgo_Alto$Edad)
shapiro.test(riesgo_Alto$H)
shapiro.test(riesgo_Alto$P)
shapiro.test(riesgo_Alto$R)
summary(riesgo_Medio)
scatterplotMatrix(riesgo_Medio[1:5])
shapiro.test(riesgo_Medio$I)
shapiro.test(riesgo_Medio$Edad)
shapiro.test(riesgo_Medio$H)
shapiro.test(riesgo_Medio$P)
shapiro.test(riesgo_Medio$R)
summary(riesgo_Bajo)
scatterplotMatrix(riesgo_Bajo[1:5])
shapiro.test(riesgo_Bajo$I)
shapiro.test(riesgo_Bajo$Edad)
shapiro.test(riesgo_Bajo$H)
shapiro.test(riesgo_Bajo$P)
shapiro.test(riesgo_Bajo$R)
datos <- dplyr::select(datos, -Sexo_MUJER, -Sexo_HOMBRE, -EC_CASADO, -EC_SOLTERO, -A_ALTO, -A_MEDIO, -A_BAJO)
datos_lda <- lda(TIPO~., data = datos)
datos_lda
datos_lda_values <- predict(datos_lda)
ldahist(data = datos_lda_values$x[,1], g = datos$TIPO)
ldahist(data = datos_lda_values$x[,2], g = datos$TIPO)
table(predict(datos_lda)$class, datos$TIPO)
error <- mean(datos$TIPO != datos_lda_values$class) * 100
paste("Error: ", error, "%")
datos_qda <- qda(TIPO~., data = datos)
datos_qda
datos_qda_values <- predict(datos_qda)
table(datos_qda_values$class, datos$TIPO)
error <- mean(datos$TIPO != datos_qda_values$class) * 100
paste("Error: ", error, "%")
train <- sample(nrow(datos), 0.7*nrow(datos)) # muestra aleatoria de aprendizaje del arbol
datos_train <- datos[train,] # muestra de entrenamiento
datos_validate <- datos[-train,] # muestra de validaciÃ³n
table(datos_train$TIPO)
table(datos_validate$TIPO)
arbol <- rpart(TIPO ~ ., data = datos_train, method = "class",
parms = list(split = "information"))
print(arbol)
summary(arbol)
train <- sample(nrow(datos), 0.8*nrow(datos)) # muestra aleatoria de aprendizaje del arbol
datos_train <- datos[train,] # muestra de entrenamiento
datos_validate <- datos[-train,] # muestra de validaciÃ³n
table(datos_train$TIPO)
table(datos_validate$TIPO)
train <- sample(nrow(datos), 0.8*nrow(datos)) # muestra aleatoria de aprendizaje del arbol
datos_train <- datos[train,] # muestra de entrenamiento
datos_validate <- datos[-train,] # muestra de validaciÃ³n
table(datos_train$TIPO)
table(datos_validate$TIPO)
rpart.plot(arbol)
fit.ctree <- ctree(as.factor(TIPO)~., data = datos_train)
plot(fit.ctree, main = "Conditional Inference Tree")
ctree.pred <- predict(fit.ctree, datos_validate, type = "response")
ctree.perf <- table(datos_validate$TIPO, ctree.pred,
dnn = c("Actual", "Predicted"))
ctree.perf
breast <- read.table(url, sep = ",", header = FALSE, na.strings = "?")
loc <- "http://archive.ics.uci.edu/ml/machine-learning-databases/"
ds <- "breast-cancer-wisconsin/breast-cancer-wisconsin.data"
url <- paste(loc, ds, sep = "")
breast <- read.table(url, sep = ",", header = FALSE, na.strings = "?")
names(breast) <- c("ID", "clumpThickness", "sizeUniformity",
"shapeUniformity", "maginalAdhesion",
"singleEpithelialCellSize", "bareNuclei",
"blandChromatin", "normalNucleoli", "mitosis", "class")
df <- breast[-1]
df$class <- factor(df$class, levels = c(2,4),
labels = c("benigno", "maligno"))
summary(df)
str(df)
table(df$class)
set.seed(1234)
train <- sample(nrow(df), 0.7*nrow(df))
df.train <- df[train,] # muestra de entrenamiento
df.validate <- df[-train,] # muestra de validaciÃ³n
table(df.train$class)
table(df.validate$class)
library(rpart)
arbol <- rpart(class ~ ., data = df.train, method = "class",
parms = list(split = "information"))
print(arbol)
summary(arbol)
arbol$cptable
plotcp(arbol)
arbol.podado <- prune(arbol, cp = .04117647)
library(rpart.plot)
# represento arbol sin podar
prp(arbol, type = 2, extra = 104,
fallen.leaves = TRUE, main = "Decision Tree")
# representamos el arbol pordado
prp(arbol.podado, type = 2, extra = 104,
fallen.leaves = TRUE, main = "Decision Tree")
datos <- read_excel("Datos tarea1.xlsx")
datos <- dplyr::select(datos, -Sexo, -EC, -A)
train <- sample(nrow(datos), 0.8*nrow(datos)) # muestra aleatoria de aprendizaje del arbol
datos_train <- datos[train,] # muestra de entrenamiento
datos_validate <- datos[-train,] # muestra de validaciÃ³n
table(datos_train$TIPO)
table(datos_validate$TIPO)
arbol <- rpart(TIPO ~ ., data = datos_train, method = "class",
parms = list(split = "information"))
print(arbol)
summary(arbol)
rpart.plot(arbol)
library(rpart)
library(rpart.plot)
library(partykit)
library(party)
library(readxl)
library(fastDummies)
library(ggplot2)
library(MASS)
library(biotools)
library(car)
set.seed(1234)
datos <- read_excel("Datos tarea1.xlsx")
datos <- dplyr::select(datos, -Sexo, -EC, -A)
View(datos)
train <- sample(nrow(datos), 0.8*nrow(datos)) # muestra aleatoria de aprendizaje del arbol
datos_train <- datos[train,] # muestra de entrenamiento
datos_validate <- datos[-train,] # muestra de validaciÃ³n
table(datos_train$TIPO)
table(datos_validate$TIPO)
arbol <- rpart(TIPO ~ ., data = datos_train, method = "class",
parms = list(split = "information"))
print(arbol)
summary(arbol)
rpart.plot(arbol)
library(rpart)
library(rpart.plot)
library(partykit)
library(party)
library(readxl)
library(fastDummies)
library(ggplot2)
library(MASS)
library(biotools)
library(car)
set.seed(1234)
datos <- read_excel("Datos tarea1.xlsx")
datos <- dummy_columns(datos, select_columns = c("Sexo", "EC", "A"))
datos$Sexo_HOMBRE <- as.factor(datos$Sexo_HOMBRE)
datos$Sexo_MUJER <- as.factor(datos$Sexo_MUJER)
datos$EC_SOLTERO <- as.factor(datos$EC_SOLTERO)
datos$EC_CASADO <- as.factor(datos$EC_CASADO)
datos$A_BAJO <- as.factor(datos$A_BAJO)
datos$A_MEDIO <- as.factor(datos$A_MEDIO)
datos$A_ALTO <- as.factor(datos$A_ALTO)
datos <- dplyr::select(datos, -Sexo, -EC, -A)
datos <- dplyr::select(datos, -Sexo_MUJER, -Sexo_HOMBRE, -EC_CASADO, -EC_SOLTERO, -A_ALTO, -A_MEDIO, -A_BAJO)
train <- sample(nrow(datos), 0.8*nrow(datos)) # muestra aleatoria de aprendizaje del arbol
datos_train <- datos[train,] # muestra de entrenamiento
datos_validate <- datos[-train,] # muestra de validaciÃ³n
table(datos_train$TIPO)
table(datos_validate$TIPO)
arbol <- rpart(TIPO ~ ., data = datos_train, method = "class",
parms = list(split = "information"))
print(arbol)
summary(arbol)
rpart.plot(arbol)
arbol$cptable
plotcp(arbol)
arbol.podado <- prune(arbol, cp = 0.01)
plot(as.party(arbol.podado))
arbol.podado <- prune(arbol, cp = 0.04878049)
plot(as.party(arbol.podado))
arbol$cptable[which.min(arbol$cptable[,"xerror"]), "CP"]
arbol.podado <- prune(arbol, cp = 0.01)
plot(as.party(arbol.podado))
rpart.plot(arbol.podado)
arbol.podado <- prune(arbol, cp = 0.04878049)
rpart.plot(arbol.podado)
arbol1 <- predict(arbol, datos_validate, type = "TIPO")
arbol1 <- predict(arbol, datos_validate, type = "class")
arbol2 <- predict(arbol.podado, datos_validate, type = "class")
table(datos_validate$class, arbol1, dnn = c("Actual", "Predicted"))
table(datos_validate$TIPO, arbol1, dnn = c("Actual", "Predicted"))
error <- mean(datos_validate$TIPO != arbol1$class) * 100
error <- (6 / 16) * 100
paste("Error: ", error, "%")
table(datos_validate$TIPO, arbol2, dnn = c("Actual", "Predicted"))
error <- (8 / 16) * 100
paste("Error: ", error, "%")
knitr::opts_chunk$set(echo = TRUE)
library(rpart)
library(rpart.plot)
library(partykit)
library(party)
library(readxl)
library(fastDummies)
library(ggplot2)
library(MASS)
library(biotools)
library(car)
set.seed(1234)
datos <- read_excel("Datos tarea1.xlsx")
View(datos)
summary(datos)
datos <- dummy_columns(datos, select_columns = c("Sexo", "EC", "A"))
datos$Sexo_HOMBRE <- as.factor(datos$Sexo_HOMBRE)
datos$Sexo_MUJER <- as.factor(datos$Sexo_MUJER)
datos$EC_SOLTERO <- as.factor(datos$EC_SOLTERO)
datos$EC_CASADO <- as.factor(datos$EC_CASADO)
datos$A_BAJO <- as.factor(datos$A_BAJO)
datos$A_MEDIO <- as.factor(datos$A_MEDIO)
datos$A_ALTO <- as.factor(datos$A_ALTO)
datos <- dplyr::select(datos, -Sexo, -EC, -A)
riesgo_Alto <- subset(datos, datos$TIPO == "Alto riesgo")
riesgo_Alto <- dplyr::select(riesgo_Alto, -c("TIPO"))
riesgo_Medio <- subset(datos, datos$TIPO == "Riesgo medio")
riesgo_Medio <- dplyr::select(riesgo_Medio, -c("TIPO"))
riesgo_Bajo <- subset(datos, datos$TIPO == "Bajo riesgo")
riesgo_Bajo <- dplyr::select(riesgo_Bajo, -c("TIPO"))
summary(riesgo_Alto)
scatterplotMatrix(riesgo_Alto[1:5])
shapiro.test(riesgo_Alto$I)
shapiro.test(riesgo_Alto$Edad)
shapiro.test(riesgo_Alto$H)
shapiro.test(riesgo_Alto$P)
shapiro.test(riesgo_Alto$R)
summary(riesgo_Medio)
scatterplotMatrix(riesgo_Medio[1:5])
shapiro.test(riesgo_Medio$I)
shapiro.test(riesgo_Medio$Edad)
shapiro.test(riesgo_Medio$H)
shapiro.test(riesgo_Medio$P)
shapiro.test(riesgo_Medio$R)
summary(riesgo_Bajo)
scatterplotMatrix(riesgo_Bajo[1:5])
shapiro.test(riesgo_Bajo$I)
shapiro.test(riesgo_Bajo$Edad)
shapiro.test(riesgo_Bajo$H)
shapiro.test(riesgo_Bajo$P)
shapiro.test(riesgo_Bajo$R)
datos <- dplyr::select(datos, -Sexo_MUJER, -Sexo_HOMBRE, -EC_CASADO, -EC_SOLTERO, -A_ALTO, -A_MEDIO, -A_BAJO)
datos_lda <- lda(TIPO~., data = datos)
datos_lda
datos_lda_values <- predict(datos_lda)
ldahist(data = datos_lda_values$x[,1], g = datos$TIPO)
table(predict(datos_lda)$class, datos$TIPO)
error <- mean(datos$TIPO != datos_lda_values$class) * 100
paste("Error: ", error, "%")
datos_qda <- qda(TIPO~., data = datos)
datos_qda
datos_qda_values <- predict(datos_qda)
table(datos_qda_values$class, datos$TIPO)
error <- mean(datos$TIPO != datos_qda_values$class) * 100
paste("Error: ", error, "%")
train <- sample(nrow(datos), 0.8*nrow(datos)) # muestra aleatoria de aprendizaje del arbol
datos_train <- datos[train,] # muestra de entrenamiento
datos_validate <- datos[-train,] # muestra de validaciÃ³n
table(datos_train$TIPO)
table(datos_validate$TIPO)
arbol <- rpart(TIPO ~ ., data = datos_train, method = "class",
parms = list(split = "information"))
print(arbol)
summary(arbol)
rpart.plot(arbol)
arbol$cptable
plotcp(arbol)
arbol.podado <- prune(arbol, cp = 0.04878049)
rpart.plot(arbol.podado)
arbol1 <- predict(arbol, datos_validate, type = "class")
arbol2 <- predict(arbol.podado, datos_validate, type = "class")
table(datos_validate$TIPO, arbol1, dnn = c("Actual", "Predicted"))
error <- (5 / 16) * 100
paste("Error: ", error, "%")
error <- (6 / 16) * 100
paste("Error: ", error, "%")
