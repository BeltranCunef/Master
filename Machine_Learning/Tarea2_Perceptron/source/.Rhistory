b <- b + learning.rate * y[i] * R^2
iterations <- iterations + 1
# check the number of iterations, I want to save the plane every 10 iterations
if (iterations %% 10 == 0) {
linea[i,] <- c(w[1]/EuclideanNorm(w), w[2]/EuclideanNorm(w), b/EuclideanNorm(w))
}
}
}
}
s = EuclideanNorm(w)
return(list(w = w/s, b = b/s, steps = iterations, linea = na.omit(linea)))
}
the_perceptron <- PerceptronFunction(x,y)
predicted_y <- ClassifyLinear(x, the_perceptron$w, the_perceptron$b)
# error
print(sum(abs(y - predicted_y)))
Dibujar <- function(x,y,linea) {
for (i in seq(1,nrow(linea))) {
plot(x, pch = ifelse(y > 0, "+", "-"), cex = 2)
abline(-linea[i,3]/linea[i,2],-linea[i,1]/linea[i,2])
}
}
Dibujar(x, y, the_perceptron$linea)
the_perceptron$linea
Dibujar(x, y, the_perceptron$linea)
Dibujar(x, y, the_perceptron$linea)
PerceptronFunction <- function(x, y, learning.rate = 1) {
# The next dataframe is used to save the values of w and b in order to plot the line I will
# save the plane every 10 iterations
linea <- data.frame("x1" = 0, "x2" = 0, "b" = 0)
w = vector(length = ncol(x)) # initialize w
b = 0 # Initialize b
iterations = 0 # count iterations
R = max(apply(x, 1, EuclideanNorm)) # maximum distance to the plane
convergence = FALSE # to enter the while loop
while (!convergence) {
convergence = TRUE # hopes luck
yc <- ClassifyLinear(x, w, b)
for (i in 1:nrow(x)) {
if (y[i] != yc[i]) {
convergence <- FALSE
w <- w + learning.rate * y[i] * x[i,]
b <- b + learning.rate * y[i] * R^2
iterations <- iterations + 1
linea[i,] <- c(w[1]/EuclideanNorm(w), w[2]/EuclideanNorm(w), b/EuclideanNorm(w))
}
}
}
s = EuclideanNorm(w)
return(list(w = w/s, b = b/s, steps = iterations, linea = linea))
}
DistanceFromPlane = function(z, w, b) {
sum(z * w) + b # mido la distancia de los puntos al plano
}
ClassifyLinear = function(x, w, b) {
distances = apply(x, 1, DistanceFromPlane, w, b) # x es el dataframe, a cada registro le aplicas la                                                       funcion al plano que forman la w con la b
return(ifelse(distances < 0, -1, +1))
}
EuclideanNorm <- function(x) {
return(sqrt(sum(x * x)))
}
# PerceptronFunction <- function(x, y, learning.rate = 1) {
#   w = vector(length = ncol(x)) # initialize w, vector vacio que incluye tantos valores como variables                                    tiene x
#   b = 0 # Initialize b
#   iterations = 0 # count iterations
#   R = max(apply(x, 1, EuclideanNorm)) # calculo la maxima distancia
#   convergence = FALSE # to enter the while loop
#   while (!convergence) {
#     convergence = TRUE # hopes luck
#     yc <- ClassifyLinear(x, w, b) # predicciones, resultado de los puntos respecto al plano
#     for (i in 1:nrow(x)) { # para cada punto mira si esta bien predicho
#       if (y[i] != yc[i]) { # deja de converger en el momento en que todas las predicciones acierten
#         convergence <- FALSE
#
#         # actualizamos el plano en base a los valores originales y la tasa de aprendizaje
#
#         w <- w + learning.rate * y[i] * x[i,] # valor original + tasa de aprendizaje * lo que me                                                       deberia haber dado para el valor que deberia
#         b <- b + learning.rate * y[i] * R^2
#
#         iterations <- iterations + 1
#       }
#     }
#   }
# s = EuclideanNorm(w)
# return(list(w = w/s, b = b/s, steps = iterations))
# }
# very easy
# x2 = x1 + 1/2
x1 <- runif(50,-1,1)
x2 <- runif(50,-1,1)
x <- cbind(x1,x2)
y <- ifelse(x2 > 0.5 + x1, +1, -1)
PerceptronFunction <- function(x, y, learning.rate = 1) {
# The next dataframe is used to save the values of w and b in order to plot the line I will
# save the plane every 10 iterations
linea <- data.frame("x1" = 0, "x2" = 0, "b" = 0)
w = vector(length = ncol(x)) # initialize w
b = 0 # Initialize b
iterations = 0 # count iterations
R = max(apply(x, 1, EuclideanNorm)) # maximum distance to the plane
convergence = FALSE # to enter the while loop
while (!convergence) {
convergence = TRUE # hopes luck
yc <- ClassifyLinear(x, w, b)
for (i in 1:nrow(x)) {
if (y[i] != yc[i]) {
convergence <- FALSE
w <- w + learning.rate * y[i] * x[i,]
b <- b + learning.rate * y[i] * R^2
iterations <- iterations + 1
linea[i,] <- c(w[1]/EuclideanNorm(w), w[2]/EuclideanNorm(w), b/EuclideanNorm(w))
}
}
}
s = EuclideanNorm(w)
return(list(w = w/s, b = b/s, steps = iterations, linea = linea))
}
the_perceptron <- PerceptronFunction(x,y)
predicted_y <- ClassifyLinear(x, the_perceptron$w, the_perceptron$b)
# error
print(sum(abs(y - predicted_y)))
Dibujar <- function(x,y,linea) {
for (i in seq(1,nrow(linea))) {
plot(x, pch = ifelse(y > 0, "+", "-"), cex = 2)
abline(-linea[i,3]/linea[i,2],-linea[i,1]/linea[i,2])
}
}
Dibujar(x, y, the_perceptron$linea)
knitr::opts_chunk$set(echo = TRUE)
DistanceFromPlane = function(z, w, b) {
sum(z * w) + b # mido la distancia de los puntos al plano
}
ClassifyLinear = function(x, w, b) {
distances = apply(x, 1, DistanceFromPlane, w, b) # x es el dataframe, a cada registro le aplicas la                                                       funcion al plano que forman la w con la b
return(ifelse(distances < 0, -1, +1))
}
EuclideanNorm <- function(x) {
return(sqrt(sum(x * x)))
}
# PerceptronFunction <- function(x, y, learning.rate = 1) {
#   w = vector(length = ncol(x)) # initialize w, vector vacio que incluye tantos valores como variables                                    tiene x
#   b = 0 # Initialize b
#   iterations = 0 # count iterations
#   R = max(apply(x, 1, EuclideanNorm)) # calculo la maxima distancia
#   convergence = FALSE # to enter the while loop
#   while (!convergence) {
#     convergence = TRUE # hopes luck
#     yc <- ClassifyLinear(x, w, b) # predicciones, resultado de los puntos respecto al plano
#     for (i in 1:nrow(x)) { # para cada punto mira si esta bien predicho
#       if (y[i] != yc[i]) { # deja de converger en el momento en que todas las predicciones acierten
#         convergence <- FALSE
#
#         # actualizamos el plano en base a los valores originales y la tasa de aprendizaje
#
#         w <- w + learning.rate * y[i] * x[i,] # valor original + tasa de aprendizaje * lo que me                                                       deberia haber dado para el valor que deberia
#         b <- b + learning.rate * y[i] * R^2
#
#         iterations <- iterations + 1
#       }
#     }
#   }
# s = EuclideanNorm(w)
# return(list(w = w/s, b = b/s, steps = iterations))
# }
# very easy
# x2 = x1 + 1/2
x1 <- runif(50,-1,1)
x2 <- runif(50,-1,1)
x <- cbind(x1,x2)
y <- ifelse(x2 > 0.5 + x1, +1, -1)
PerceptronFunction <- function(x, y, learning.rate = 1) {
# The next dataframe is used to save the values of w and b in order to plot the line I will
# save the plane every 10 iterations
linea <- data.frame("x1" = 0, "x2" = 0, "b" = 0)
w = vector(length = ncol(x)) # initialize w
b = 0 # Initialize b
iterations = 0 # count iterations
R = max(apply(x, 1, EuclideanNorm)) # maximum distance to the plane
convergence = FALSE # to enter the while loop
while (!convergence) {
convergence = TRUE # hopes luck
yc <- ClassifyLinear(x, w, b)
for (i in 1:nrow(x)) {
if (y[i] != yc[i]) {
convergence <- FALSE
w <- w + learning.rate * y[i] * x[i,]
b <- b + learning.rate * y[i] * R^2
iterations <- iterations + 1
linea[i,] <- c(w[1]/EuclideanNorm(w), w[2]/EuclideanNorm(w), b/EuclideanNorm(w))
}
}
}
s = EuclideanNorm(w)
return(list(w = w/s, b = b/s, steps = iterations, linea = linea))
}
Dibujar <- function(x,y,linea) {
for (i in seq(1,nrow(linea))) {
plot(x, pch = ifelse(y > 0, "+", "-"), xlim = c(-5,5), ylim = c(-5,5),  cex = 2)
abline(-linea[i,3]/linea[i,2],-linea[i,1]/linea[i,2])
}
}
the_perceptron <- PerceptronFunction(x,y)
predicted_y <- ClassifyLinear(x, the_perceptron$w, the_perceptron$b)
# error
print(sum(abs(y - predicted_y)))
Dibujar(x, y, the_perceptron$linea)
install.packages("mlbench")
#---------- load library ----------
if("mlbench" %in% rownames(installed.packages()) == FALSE) {install.packages("mlbench", dependencies = TRUE)}
library('mlbench')
# load data
data(BostonHousing2)
# info about the data
str(BostonHousing2)
summary(BostonHousing2)
# Using cut
BostonHousing2$age_range <- cut(BostonHousing2$age, breaks = c(-Inf, 20, 30, 40, 60, Inf),
labels = c(0, 1, 2, 3, 4),
right = FALSE)
BostonHousing2$age <- NULL
BostonHousing2$homes_range <- as.factor(ifelse(BostonHousing2$medv <
((max(BostonHousing2$medv) - min(BostonHousing2$medv))/2), 0, 1))
# delete medv variable
BostonHousing2$medv <- NULL
BostonHousing2$homes_range <- as.factor(ifelse(BostonHousing2$medv <
((max(BostonHousing2$medv) - min(BostonHousing2$medv))/2), 0, 1))
plot(BostonHousing2$homes_range)
title(main = "Home range", xlab = "Home Range", ylab = "frequency")
#by age
plot(BostonHousing2[BostonHousing2$age_range == 0, ncol(BostonHousing2)])
title(main = "Home Range for under 20", xlab = "Home Range", ylab = "frequency")
ages_na <- which(is.na(BostonHousing2$age_range) == TRUE)
homes_na <- which(is.na(BostonHousing2$homes_range) == TRUE)
# no NAs in this case
# divide into test and training sets
# create new col "train"" and assign 1 or 0 in 80/20 proportion via random uniform dist
BostonHousing2[, "train"] <- ifelse(runif(nrow(BostonHousing2)) < 0.80, 1, 0)
# get col number of train / test indicator column (needed later)
trainColNum <- grep("train", names(BostonHousing2))
# separate training and test sets and remove training column before modeling
trainBostonHousing2 <-BostonHousing2[BostonHousing2$train == 1,-trainColNum]
testBostonHousing2 <- BostonHousing2[BostonHousing2$train == 0,-trainColNum]
if("e1071" %in% rownames(installed.packages()) == FALSE) {install.packages("e1071", dependencies = TRUE)}
library('e1071')
naive_bayes_model <- naiveBayes(homes_range ~., data = trainBostonHousing2)
naive_bayes_model
summary(naive_bayes_model)
str(naive_bayes_model)
naive_bayes_test_predict <- predict(naive_bayes_model, testBostonHousing2[, -ncol(testBostonHousing2)])
#confusion matrix
table(pred = naive_bayes_test_predict, true = testBostonHousing2$homes_range)
#fraction of correct predictions
mean(naive_bayes_test_predict == testBostonHousing2$homes_range)
knitr::opts_chunk$set(echo = TRUE)
DistanceFromPlane = function(z, w, b) {
sum(z * w) + b # mido la distancia de los puntos al plano
}
ClassifyLinear = function(x, w, b) {
distances = apply(x, 1, DistanceFromPlane, w, b) # x es el dataframe, a cada registro le aplicas la                                                       funcion al plano que forman la w con la b
return(ifelse(distances < 0, -1, +1))
}
EuclideanNorm <- function(x) {
return(sqrt(sum(x * x)))
}
# PerceptronFunction <- function(x, y, learning.rate = 1) {
#   w = vector(length = ncol(x)) # initialize w, vector vacio que incluye tantos valores como variables                                    tiene x
#   b = 0 # Initialize b
#   iterations = 0 # count iterations
#   R = max(apply(x, 1, EuclideanNorm)) # calculo la maxima distancia
#   convergence = FALSE # to enter the while loop
#   while (!convergence) {
#     convergence = TRUE # hopes luck
#     yc <- ClassifyLinear(x, w, b) # predicciones, resultado de los puntos respecto al plano
#     for (i in 1:nrow(x)) { # para cada punto mira si esta bien predicho
#       if (y[i] != yc[i]) { # deja de converger en el momento en que todas las predicciones acierten
#         convergence <- FALSE
#
#         # actualizamos el plano en base a los valores originales y la tasa de aprendizaje
#
#         w <- w + learning.rate * y[i] * x[i,] # valor original + tasa de aprendizaje * lo que me                                                       deberia haber dado para el valor que deberia
#         b <- b + learning.rate * y[i] * R^2
#
#         iterations <- iterations + 1
#       }
#     }
#   }
# s = EuclideanNorm(w)
# return(list(w = w/s, b = b/s, steps = iterations))
# }
PerceptronFunction <- function(x, y, learning.rate = 1) {
# The next dataframe is used to save the values of w and b in order to plot the line
linea <- data.frame("x1" = 0, "x2" = 0, "b" = 0)
w = vector(length = ncol(x)) # initialize w
b = 0 # Initialize b
iterations = 0 # count iterations
R = max(apply(x, 1, EuclideanNorm)) # maximum distance to the plane
convergence = FALSE # to enter the while loop
while (!convergence) {
convergence = TRUE # hopes luck
yc <- ClassifyLinear(x, w, b)
for (i in 1:nrow(x)) {
if (y[i] != yc[i]) {
convergence <- FALSE
w <- w + learning.rate * y[i] * x[i,]
b <- b + learning.rate * y[i] * R^2
iterations <- iterations + 1
linea[i,] <- c(w[1]/EuclideanNorm(w), w[2]/EuclideanNorm(w), b/EuclideanNorm(w))
}
}
}
s = EuclideanNorm(w)
return(list(w = w/s, b = b/s, steps = iterations, linea = linea))
}
set.seed(123)
# very easy
# x2 = x1 + 1/2
x1 <- runif(50,-1,1)
x2 <- runif(50,-1,1)
x <- cbind(x1,x2)
y <- ifelse(x2 > 0.5 + x1, +1, -1)
the_perceptron <- PerceptronFunction(x,y)
predicted_y <- ClassifyLinear(x, the_perceptron$w, the_perceptron$b)
# error
print(sum(abs(y - predicted_y)))
Dibujar <- function(x,y,linea) {
for (i in seq(1,nrow(linea))) {
plot(x, pch = ifelse(y > 0, "+", "-"), xlim = c(-5,5), ylim = c(-5,5),  cex = 2)
abline(-linea[i,3]/linea[i,2],-linea[i,1]/linea[i,2])
}
}
Dibujar(x, y, the_perceptron$linea)
PerceptronFunction <- function(x, y, learning.rate = 1) {
# The next dataframe is used to save the values of w and b in order to plot the line
linea <- data.frame("x1" = 0, "x2" = 0, "b" = 0)
w = vector(length = ncol(x)) # initialize w
b = 0 # Initialize b
iterations = 0 # count iterations
R = max(apply(x, 1, EuclideanNorm)) # maximum distance to the plane
convergence = FALSE # to enter the while loop
while (!convergence) {
convergence = TRUE # hopes luck
yc <- ClassifyLinear(x, w, b)
for (i in 1:nrow(x)) {
if (y[i] != yc[i]) {
convergence <- FALSE
w <- w + learning.rate * y[i] * x[i,]
b <- b + learning.rate * y[i] * R^2
iterations <- iterations + 1
linea[i,] <- c(w[1], w[2], b)
}
}
}
s = EuclideanNorm(w)
return(list(w = w/s, b = b/s, steps = iterations, linea = linea))
}
the_perceptron <- PerceptronFunction(x,y)
predicted_y <- ClassifyLinear(x, the_perceptron$w, the_perceptron$b)
# error
print(sum(abs(y - predicted_y)))
Dibujar(x, y, the_perceptron$linea)
PerceptronFunction <- function(x, y, learning.rate = 1) {
# The next dataframe is used to save the values of w and b in order to plot the line
linea <- data.frame("x1" = 0, "x2" = 0, "b" = 0)
w = vector(length = ncol(x)) # initialize w
b = 0 # Initialize b
iterations = 0 # count iterations
R = max(apply(x, 1, EuclideanNorm)) # maximum distance to the plane
convergence = FALSE # to enter the while loop
while (!convergence) {
convergence = TRUE # hopes luck
yc <- ClassifyLinear(x, w, b)
for (i in 1:nrow(x)) {
if (y[i] != yc[i]) {
convergence <- FALSE
w <- w + learning.rate * y[i] * x[i,]
b <- b + learning.rate * y[i] * R^2
iterations <- iterations + 1
linea[i,] <- c(w[1], w[2], b)
}
}
}
s = EuclideanNorm(w)
return(list(w = w/s, b = b/s, steps = iterations, linea = linea/s))
}
Dibujar(x, y, the_perceptron$linea)
PerceptronFunction <- function(x, y, learning.rate = 1) {
# The next dataframe is used to save the values of w and b in order to plot the line
linea <- data.frame("x1" = 0, "x2" = 0, "b" = 0)
w = vector(length = ncol(x)) # initialize w
b = 0 # Initialize b
iterations = 0 # count iterations
R = max(apply(x, 1, EuclideanNorm)) # maximum distance to the plane
convergence = FALSE # to enter the while loop
while (!convergence) {
convergence = TRUE # hopes luck
yc <- ClassifyLinear(x, w, b)
for (i in 1:nrow(x)) {
if (y[i] != yc[i]) {
convergence <- FALSE
w <- w + learning.rate * y[i] * x[i,]
b <- b + learning.rate * y[i] * R^2
iterations <- iterations + 1
linea[i,] <- c(w[1]/EuclideanNorm(w), w[2]/EuclideanNorm(w), b/EuclideanNorm(w))
}
}
}
s = EuclideanNorm(w)
return(list(w = w/s, b = b/s, steps = iterations, linea = linea))
}
DistanceFromPlane = function(z, w, b) {
sum(z * w) + b # mido la distancia de los puntos al plano
}
ClassifyLinear = function(x, w, b) {
distances = apply(x, 1, DistanceFromPlane, w, b) # x es el dataframe, a cada registro le aplicas la                                                       funcion al plano que forman la w con la b
return(ifelse(distances < 0, -1, +1))
}
EuclideanNorm <- function(x) {
return(sqrt(sum(x * x)))
}
# PerceptronFunction <- function(x, y, learning.rate = 1) {
#   w = vector(length = ncol(x)) # initialize w, vector vacio que incluye tantos valores como variables                                    tiene x
#   b = 0 # Initialize b
#   iterations = 0 # count iterations
#   R = max(apply(x, 1, EuclideanNorm)) # calculo la maxima distancia
#   convergence = FALSE # to enter the while loop
#   while (!convergence) {
#     convergence = TRUE # hopes luck
#     yc <- ClassifyLinear(x, w, b) # predicciones, resultado de los puntos respecto al plano
#     for (i in 1:nrow(x)) { # para cada punto mira si esta bien predicho
#       if (y[i] != yc[i]) { # deja de converger en el momento en que todas las predicciones acierten
#         convergence <- FALSE
#
#         # actualizamos el plano en base a los valores originales y la tasa de aprendizaje
#
#         w <- w + learning.rate * y[i] * x[i,] # valor original + tasa de aprendizaje * lo que me                                                       deberia haber dado para el valor que deberia
#         b <- b + learning.rate * y[i] * R^2
#
#         iterations <- iterations + 1
#       }
#     }
#   }
# s = EuclideanNorm(w)
# return(list(w = w/s, b = b/s, steps = iterations))
# }
set.seed(123)
# very easy
# x2 = x1 + 1/2
x1 <- runif(50,-1,1)
x2 <- runif(50,-1,1)
x3 <- runif(50,-1,1)
x <- cbind(x1,x2,x3)
y <- ifelse(x3 > 0.5 + x1 + x2, +1, -1)
Perceptron3D <- function(x, y, learning.rate = 1) {
# The next dataframe is used to save the values of w and b in order to plot the line
plane <- data.frame("x1" = 0, "x2" = 0, "x3" = 0, "b" = 0)
w = vector(length = ncol(x)) # initialize w
b = 0 # Initialize b
iterations = 0 # count iterations
R = max(apply(x, 1, EuclideanNorm)) # maximum distance to the plane
convergence = FALSE # to enter the while loop
while (!convergence) {
convergence = TRUE # hopes luck
yc <- ClassifyLinear(x, w, b)
for (i in 1:nrow(x)) {
if (y[i] != yc[i]) {
convergence <- FALSE
w <- w + learning.rate * y[i] * x[i,]
b <- b + learning.rate * y[i] * R^2
iterations <- iterations + 1
plane[i,] <- c(w[1]/EuclideanNorm(w), w[2]/EuclideanNorm(w),
w[3]/EuclideanNorm(w), b/EuclideanNorm(w))
}
}
}
s = EuclideanNorm(w)
return(list(w = w/s, b = b/s, steps = iterations, plano = plane))
}
the_perceptron_3D <- Perceptron3D(x,y)
predicted_y <- ClassifyLinear(x, the_perceptron_3D$w, the_perceptron_3D$b)
# error
print(sum(abs(y - predicted_y)))
the_perceptron_3D$steps
the_perceptron_3D
plot3d(x[,1], x[,2], x[,3], col = ifelse(y[,1] == 1, "blue", "red"))
library(rgl)
plot3d(x[,1], x[,2], x[,3], col = ifelse(y[,1] == 1, "blue", "red"))
y
y[,1]
y[1]
y
y[5]
plot3d(x[,1], x[,2], x[,3], col = ifelse(y[5] == 1, "blue", "red"))
planes3d(the_perceptron_3D$plano[5,1], the_perceptron_3D$plano[5,2],
the_perceptron_3D$plano[5,3], the_perceptron_3D$plano[5,4], alpha = 0.5,
col = 'chartreuse')
the_perceptron_3D
plot3d(x[,1], x[,2], x[,3], col = ifelse(y[5] == 1, "blue", "red"))
planes3d(the_perceptron_3D$plano[38,1], the_perceptron_3D$plano[38,2],
the_perceptron_3D$plano[38,3], the_perceptron_3D$plano[38,4], alpha = 0.5,
col = 'chartreuse')
x_y <- cbin(x,y)
x_y <- cbind(x,y)
plot3d(x_y[,1], x_[,2], x_[,3], col = ifelse(x_y[,4] == 1, "blue", "red"))
plot3d(x_y[,1], x_y[,2], x_y[,3], col = ifelse(x_y[,4] == 1, "blue", "red"))
planes3d(the_perceptron_3D$plano[38,1], the_perceptron_3D$plano[38,2],
the_perceptron_3D$plano[38,3], the_perceptron_3D$plano[38,4], alpha = 0.5,
col = 'chartreuse')
the_perceptron_3D
the_perceptron_3D$w[1]
bestplane <- data.frame("x" = the_perceptron_3D$w[1], "y" = the_perceptron_3D$w[2],
"z" = the_perceptron_3D$w[3], "b" = the_perceptron_3D$w[4])
getwd()
