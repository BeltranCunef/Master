---
title: "PrestamosGLM"
author: "Beltran Aller Lopez"
date: "3/11/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# TO DO LIST

  * TRANSFORMACION DE VARIABLES CATEGORICAS A DUMMIES
  * ANALISIS EXPLORATORIO
  * ELABORACION DEL MODELO
  * 

# LIBRARIES & SEED

```{r LIBRARIES, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(ggplot2)
library(skimr)
library(corrplot)
library(readr)
library(car)
library(ISLR)
library(fastDummies)
library(dplyr)
library(dummies)
library(boot)
library(MASS)
library(verification)
set.seed(123)
```

# DATA

Procedo a cargar el data ser, este se trata de una base de datos de aproximadamente 880 000 observaciones de 75 variables. Ofrece información acerca de los préstamos concedidos por un banco.

```{r READING DATA, echo=FALSE, message=FALSE, warning=FALSE}
loan <- read_csv("data/loan.csv", col_types = cols(int_rate = col_number(), 
    revol_util = col_number()))
```

## FILTERING & CLEANING DATA

Selecciono las variables que considero más relevantes de acuerdo a la literatura académica consultada. Estas son:

  - loan_amnt: cantidad total del préstamo.
  - int_rate: tasa de interés.
  - grade: nivel de calificación del préstamo. Este varía desde A (muy bueno) hasta G (deficiente).
  - home_ownership: indica la situación de propiedad de la vivienda habitual del prestatario.
  - annual_inc: ingresos anuales del prestatario.
  - loan_status: situación de pago del préstamo. Puede estar:
  
    * Totalmente pagado.
    * Al día.
    * Retrasado.
    * En periodo de gracia.
    * En situación de cobro improbable.
    * Emitido.
    
  - dti: ratio de endeudamiento. 
  - revol_until: ratio de utilización, cantidad del crédito usada del total disponible.

```{r FILTERING, echo=FALSE}
loan_filtered <- loan[, c("loan_amnt", "int_rate", "grade", "home_ownership", 
                            "annual_inc", "loan_status", "dti", "revol_util")]
```

A continuación observo un resumen del conjunto de datos.

```{r SUMMARISE, echo=FALSE}
skim(loan_filtered)
str(loan_filtered)
```

El data set ya filtrado está compuesto por un total de 9 variables. 4 de ellas categóricas y otras 5 numéricas. Tanto en las variables numéricas, como en las categóricas, se observa que existen datos omitidos, procedo a eliminar dichas observaciones.

```{r NA OMIT, echo=FALSE}
loan_filtered <- na.omit(loan_filtered)
```

De un total de 887 383 observaciones pasamos a 886 880 observaciones. Se observa que las variables int_rate y revol_util, en un principio estaban codificadas como factor, aunque se convirtieron a numérico. Ambas están expresandas en porcentaje, sin embargo, a raíz de su conversión sus valores aparecen modificados, los divido entre 100 para que recobren su valor original.

```{r PERCENTAGE, echo=FALSE}
loan_filtered$int_rate <- loan_filtered$int_rate / 100
loan_filtered$revol_util <- loan_filtered$revol_util / 100
```

También transformamos en dummy la variable loan_status. El método será el siguiente:
  
  - Los valores Fully Paid y Current serán dotados de un 1. Es decir, se considerarán no default. 
  - El resto de valores los consideramos como no pagados aún y por tanto default.
  
```{r DUMMY LOAN_STATUS, echo=FALSE}
loan_filtered$loan_status <- as.character(loan_filtered$loan_status)
loan_filtered$loan_status[loan_filtered$loan_status == "Current" | 
                            loan_filtered$loan_status == "Fully Paid" ] <- 1
loan_filtered$loan_status[loan_filtered$loan_status != 1] <- 0
loan_filtered$loan_status <- as.factor(loan_filtered$loan_status)
```

Transformaré también los valores correspondientes a la posesión de la casa, si es suya propia, libre de cargas, tomará el valor 1; en cualquier otro caso tomará el valor 0.

```{r DUMMY HOME_OWNERSHIP, echo=FALSE}
loan_filtered$home_ownership <- as.character(loan_filtered$home_ownership)
loan_filtered$home_ownership[loan_filtered$home_ownership == "OWN"] <- 1
loan_filtered$home_ownership[loan_filtered$home_ownership != 1] <- 0
loan_filtered$home_ownership <- as.factor(loan_filtered$home_ownership)
```

Los grados crediticios también serán transformados en dummies, pero mediante la utilización de la función dummy_cols() de la librería fastDummies.

```{r DUMMY GRADE, echo=FALSE}
loan_filtered <- dummy_cols(loan_filtered, select_columns = c("grade")) %>% 
  dplyr::select(-c("grade"))
loan_filtered$grade_B <- as.factor(loan_filtered$grade_B)
loan_filtered$grade_C <- as.factor(loan_filtered$grade_C)
loan_filtered$grade_A <- as.factor(loan_filtered$grade_A)
loan_filtered$grade_D <- as.factor(loan_filtered$grade_D)
loan_filtered$grade_E <- as.factor(loan_filtered$grade_E)
loan_filtered$grade_F <- as.factor(loan_filtered$grade_F)
loan_filtered$grade_G <- as.factor(loan_filtered$grade_G)
```

Por tanto, después de todas las tranformaciones llevadas a cabo el dataset quedaría de la siguiente forma:

```{r HEAD DATASET TRANFORMADO, echo=FALSE}
head(loan_filtered)
```

# ANALISIS EXPLORATORIO

Realizo el cálculo de la matriz de correlaciones para las variables numéricas.

```{r MATRIX CORRELATION FOR NUMERIC VARIABLES, echo=FALSE}
corrplot(round(cor(loan_filtered %>% select_at(vars(annual_inc, dti, loan_amnt, int_rate, revol_util))), 2), 
         method = 'number', type = 'lower')
```

Las variables presentan escasa relación entre sí a la vista de los valores representados en la matriz de correlaciones.

Compruebo las distribuciones de cada una de las variables numéricas, para observar si se asemejan a una normal. Para ello dibujo los histogramas y curvas de densidad de cada una de ellas.

## HISTOGRAMAS Y CURVAS DE DENSIDAD

```{r LOAN_AMNT, echo=FALSE}
hist(loan_filtered$loan_amnt, breaks = 15, 
     prob = TRUE, xlab = "LOAN_AMNT", main = "Histogram & Density Curve") 
     curve(dnorm(x, mean = mean(loan_filtered$loan_amnt), sd = sqrt(var(loan_filtered$loan_amnt))),
           add = TRUE, col = 'red')
```

```{r INT_RATE, echo=FALSE}
hist(loan_filtered$int_rate, breaks = 15, 
     prob = TRUE, xlab = "INT_RATE", main = "Histogram & Density Curve") 
     curve(dnorm(x, mean = mean(loan_filtered$int_rate), sd = sqrt(var(loan_filtered$int_rate))),
           add = TRUE, col = 'red')
```

```{r REVOL_UTIL, echo=FALSE}
hist(loan_filtered$revol_util, breaks = 250, 
     prob = TRUE, xlab = "REVOL_UTIL", main = "Histogram & Density Curve", xlim = c(0,1.5))
     curve(dnorm(x, mean = mean(loan_filtered$revol_util), sd = sqrt(var(loan_filtered$revol_util))),
           add = TRUE, col = 'red')
```

```{r DTI, echo=FALSE}
hist(loan_filtered$dti, breaks = 5000, 
     prob = TRUE, xlab = "DTI", main = "Histogram & Density Curve", xlim = c(0,50)) 
     curve(dnorm(x, mean = mean(loan_filtered$dti), sd = sqrt(var(loan_filtered$dti))),
           add = TRUE, col = 'red')
```

```{r ANUAL_INC, echo=FALSE}
hist(loan_filtered$annual_inc, breaks = 150, 
     prob = TRUE, xlab = "ANUAL_INC", main = "Histogram & Density Curve", xlim = c(0, 1000000)) 
     curve(dnorm(x, mean = mean(loan_filtered$annual_inc), sd = sqrt(var(loan_filtered$annual_inc))),
           add = TRUE, col = 'red')
```

## OUTLIERS

Se aprecia en los histogramas que existen ciertas observaciones que distorsionan la muestra. Procedo a identificarlos. Para ello primero calculo una regresión genérica con todas las variables del dataset.

```{r CALCULATEING OUTLIERS, echo=FALSE, results='hide'}
regres01 <- glm(loan_status~., data = loan_filtered, family = 'binomial')
outlierTest(regres01)
```

Elimino los outliers encontrados.

```{r DELETTING OUTLIERS, echo=FALSE}
loan_filtered <- loan_filtered[-683582,]
loan_filtered <- loan_filtered[-866483,]
```

# ELABORACIÓN DEL MODELO

Ahora procedo a determinar que variables son significativas en la regresión ya calculada.

```{r SUMMARY REGRES01, echo=FALSE}
summary(regres01)
```

Observo que todas las variables son significativas, si bien es cierto que hay grados crediticios que no lo son, por ello elimino dichos grados del dataset. Se deduce de los resultado obtenidos que, a partir de cierto grado crediticio, exactamente E, los siguientes ya se consideran irrelevantes. Es prácticamente igual de malo tener un grado crediticio E que no F o G.

```{r DELETTING GRADE F AND G, echo=FALSE}
loan_filtered <- dplyr::select(loan_filtered, -grade_F, -grade_G)
```

A continuación procedo a entrenar el modelo.

## TRAIN, TEST AND PREDICT

Para el entrenamiento del modelo divido la muestra de forma balanceada en training y test, un 70% de las observaciones son asignadas a el training y el 30% restante al test.

```{r TRAINING AND TEST, echo=FALSE}
train <- sample(nrow(loan_filtered), 0.7*nrow(loan_filtered))

loan_train <- loan_filtered[train,] # muestra de entrenamiento

loan_test <- loan_filtered[-train,] # muestra de test
```

Ahora calculo un nuevo modelo sobre la muestra de entrenamiento. 

```{r REGRES_TRAINED, echo=FALSE, warning=FALSE}

# regres_trained sera el modelo calculado sobre la muestra de entrenamiento

regres_trained <- glm(loan_status~., data = loan_train, family = 'binomial')
regres_trained$coefficients
```

El modelo obtenido a través de la regresión calculada sobre el training es el siguiente:

Default = 5.54Intercep + 5.16e-6loan_amnt - 18.87int_rate + 5.36e-2home_ownership + 2.22e-6annual_inc
+ 2.96e-3dti - 5.69e-2revol_util - 1.12gradeA - 1.03gradeB - 0.82gradeC - 0.33gradeE - 0.6gradeD

Debemos tener en cuenta que la variable home_ownership toma valor 1 si tiene una casa en posesión o 0 si no la tiene, por tanto afecta positivamente a la probabilidad de devolver el préstamo. También hay que tener en cuenta que la pertenencia a un grado crediticio excluye de la pertenencia a cualquier otro. Y estos toman valores 1 o 0.

A continuación realizo la predicción sobre el test y calculo el error de la regresión. Establezco un cutt off por defecto en 0.7

```{r PREDICT, echo = FALSE, message = FALSE, warning = FALSE}

# Predecir el test.  
glm.probs <- predict(regres_trained, loan_test, type = "response")

# Crear un vector para guardar los resultados (No default) 
glm.pred <- rep("0", nrow(loan_test))

# Reemplazar NO por YES cuando la probabilidad es mayor del 70%
glm.pred[glm.probs > .7] = "1"

# Crear un vector con los resultados
defaultVector <- loan_test$loan_status 


# Calcula la media  
mean(glm.pred == defaultVector)
```

```{r ERROR K-FOLD, echo = FALSE, message = FALSE, warning = FALSE, results='hide'}

# Crear un vector para guardar los resultados
cv.error <- rep(0,3)


# Guardar los resultados para cada K  validation set. K= {3,5,10} 
cv.error[1] <- cv.glm(loan_train, regres_trained, K = 3)$delta[1]
cv.error[2] <- cv.glm(loan_train, regres_trained, K = 5)$delta[1]
cv.error[3] <- cv.glm(loan_train, regres_trained, K = 10)$delta[1]

cv.error
```

Calculo el porcentaje de acierto con K-fold.

```{r MEAN K-FOLD, echo=FALSE}
1 - mean(cv.error)
```

Obtengo un porcentaje de acierto del 92,20% aproximadamente.

## HISTOGRAMAS DE LA PREDICCION

```{r HISTOGRAMA, echo=FALSE, results='hide'}
hist(predict(regres_trained))
```

Para cada odd ratio dentro de la muestra deseo obtener P(y=1), para ello aplico la función inversa.

```{r HISTOGRAMA DE LA FUNCION INVERSA, echo=FALSE}
hist(predict(regres_trained,type = "response"))
```

Debo establecer una regla de decisión de clase binaria, es decir, un cut off. Este me servirá para decidir a partir de que valores considero que se produce un default y a partir de cuáles no. Realizo varias pruebas. En primer lugar establezo un cut off de 0.5. Los valores TRUE serán considerados como no default y los FALSE como default.

```{r CUT OFF 0.5, echo=FALSE}
table(predict(regres_trained,type = "response") > 0.5)
```

Subo el cut off a 0.7.

```{r CUT OFF 0.7, echo=FALSE}
table(predict(regres_trained,type = "response") > 0.7)
```

Pruebo subiendo el cut off a 0.9.

```{r CUT OFF 0.9, echo=FALSE}
table(predict(regres_trained,type = "response") > 0.90)
```

## PREDICCION DENTRO Y FUERA DE LA MUESTRA

Procedo a poner a prueba el modelo tanto dentro como fuera de la muestra.

### DENTRO DE LA MUESTRA

Establezco el punto de corte en 0.9, la sentencia genera un vector lógico para las observaciones del conjunto de entrenamiento con una probabilidad mayor a 0.9, dicho vector se transforma en un vector numérico de 0 y 1.

```{r PROBABILITIES INSAMPLE, echo=FALSE}
prob.regres_trained.insample <- predict(regres_trained, type = "response")
predicted.regres_trained.insample <- prob.regres_trained.insample > 0.9
predicted.regres_trained.insample <- as.numeric(predicted.regres_trained.insample)
```

calculo la matriz de confusión.

```{r CONFUSSION MATRIX INSAMPLE, echo=FALSE}
table(loan_train$loan_status, predicted.regres_trained.insample, dnn = c("Truth","Predicted"))
```

Ahora calculo la tasa de error.

```{r ERROR INSAMPLE, echo=FALSE}
mean(ifelse(loan_train$loan_status != predicted.regres_trained.insample, 1, 0))
```

La tase de error es de un 31,72% aproximadamente.

### FUERA DE LA MUESTRA

```{r PROBABILITIES OUTSAMPLE, echo=FALSE}
prob.regres_trained.outsample <- predict(regres_trained,loan_test, type = "response")
predicted.regres_trained.outsample <-  prob.regres_trained.outsample > 0.9
predicted.regres_trained.outsample <- as.numeric(predicted.regres_trained.outsample)
```

La matriz de confusión es la siguiente:

```{r CONFUSSION MATRIX OUTSAMPLE}
table(loan_test$loan_status, predicted.regres_trained.outsample, dnn = c("Truth","Predicted"))
```

Calculo la tase de error fuera de la muestra.

```{r ERROR OUTSAMPLE}
mean(ifelse(loan_test$loan_status != predicted.regres_trained.outsample, 1, 0))
```

La tasa de error fuera de la muestra es de un 31,62% proximadamente.

# CURVA ROC

Uno de los parámetros para evaluar la bondad del ajuste es llevar a cabo el trazado de la curva ROC y posteriormente el cálculo del área por debajo de esta. 

En primer lugar represento la curva ROC.

```{r ROC, echo=FALSE}
roc.plot(loan_test$loan_status == '1', prob.regres_trained.outsample)
```

El valor obtenido para el área por debajo de la curva es de 0.659

```{r VALUES ROC, echo=FALSE, results='hide'}
roc.plot(loan_test$loan_status == '1', prob.regres_trained.outsample)$roc.vol
```

# CUT OFF OPTIMO

La siguiente función me permite calcular el cut off óptimo para mi modelo. Este será aquel que minimiza el coste de la función, es decir, el coste de equivocarnos en la predicción.

```{r DEFINING CUT OFF}

#define the searc grid from 0.01 to 0.99

searchgrid = seq(0.01, 0.99, 0.01)

#result is a 99x2 matrix, the 1st col stores the cut-off p, the 2nd column stores the cost

result = cbind(searchgrid, NA)

#in the cost function, both r and pi are vectors, r=truth, pi=predicted probability

cost1 <- function(r, pi){
  weight1 = 10
  weight0 = 1
  c1 = (r == 1) & (pi < pcut) #logical vector - true if actual 1 but predict 0
  c0 = (r == 0) & (pi > pcut) #logical vector - true if actual 0 but predict 1
  return(mean(weight1*c1 + weight0*c0))
}

regres_cutoff <- glm(loan_status~., data = loan_train, family = 'binomial')

prob <- predict(regres_cutoff, type = "response")

for (i in 1:length(searchgrid))
{
  pcut <- result[i,1]
  
  #assign the cost to the 2nd col
  
  result[i,2] <- cost1(loan_train$loan_status, prob)
}

plot(result, ylab = "Cost in Training Set")
```

```{r RESULT CUT OFF}
result[which.min(result[,2]),]
```

